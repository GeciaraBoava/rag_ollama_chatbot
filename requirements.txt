# ============================================
# RAG Chatbot - Dependências Compatíveis
# Testado com Python 3.11.9
# Versões verificadas no PyPI
# ============================================

# Núcleo LlamaIndex (sem fixar versão menor)
llama-index-core>=0.11.0,<0.12.0
llama-index>=0.11.0,<0.12.0

# Integrações LlamaIndex
llama-index-embeddings-huggingface>=0.3.0,<0.4.0
llama-index-llms-ollama>=0.3.0,<0.4.0
llama-index-vector-stores-faiss>=0.2.0,<0.3.0

# Ollama (cliente Python)
ollama>=0.3.0,<0.4.0

# Embeddings e Modelos
sentence-transformers>=3.0.0,<4.0.0
transformers>=4.40.0,<5.0.0
torch>=2.1.0,<3.0.0
safetensors>=0.4.0,<0.5.0

# FAISS (busca vetorial)
faiss-cpu>=1.8.0,<2.0.0

# Manipulação de documentos
pypdf>=4.0.0,<6.0.0
python-docx>=1.1.0,<2.0.0

# Utilitários gerais
numpy>=1.24.0,<2.0.0
python-dotenv>=1.0.0,<2.0.0
nltk>=3.8.0,<4.0.0
tiktoken>=0.5.0,<1.0.0
requests>=2.31.0,<3.0.0

# Dependências adicionais
huggingface-hub>=0.20.0,<1.0.0
tokenizers>=0.19.0,<1.0.0

# ============================================
# Instalação:
# pip install -r requirements.txt
#
# Após instalar, baixe o modelo Ollama:
# ollama pull llama3.2:3b
# ============================================